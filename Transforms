import torch
import torchvision.transforms as transforms

#define the function that will give me the transforms for the train on the food101 dataset.
def get_train_transforms():
    return transforms.Compose([
        transforms.ToPILImage(), #convert the tensor to PIL format.
        transforms.Resize(256),
        transforms.RandomCrop(224),  # Random clipping for data augmentation
        transforms.RandomHorizontalFlip(p=0.5),  # Random horizontal flip in 50% of cases
        # Some images are grayscale, I force their conversion
        transforms.Lambda(lambda img: img.convert("RGB")),
        transforms.ColorJitter(
            brightness=0.1,  # Slight variation in brightness
            contrast=0.1,  # Slight variation in contrast
            saturation=0.1,  # Slight variation in saturation
            hue=0.05  # Minimal variation in tone (most sensitive).
        ),
        transforms.ToTensor(),  # Converts to tensor [0,1]
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],  # ImageNet's RGB media
            std=[0.229, 0.224, 0.225]  # RGB standard deviation of ImageNet
        )
    ])

#define the function that will give me the transforms for the test on the food101 dataset.
def get_test_transforms():
    return transforms.Compose([
        transforms.ToPILImage(), 
        transforms.Resize(256),  
        transforms.CenterCrop(224),  # Crop central instead of random
        # Some images are grayscale, I force their conversion
        transforms.Lambda(lambda img: img.convert("RGB")),
        transforms.ToTensor(),  # Converte in tensore [0,1]
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],  # Same training normalization statistics.
            std=[0.229, 0.224, 0.225]
        )
    ])

def get_ood_transforms():
    return transforms.Compose([
        # SVHN in torchvision already returns GDP images, so no need for ToPILImage
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.Lambda(lambda img: img.convert("RGB")),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        )
    ])

# Support function to display normalized images.
def denormalize(tensor):
    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
    return tensor * std + mean
